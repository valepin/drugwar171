\documentclass{article}[11 pt]
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{color}
\usepackage{graphicx,psfrag,pst-node,subfigure,verbatim}
\usepackage{amsmath,bbm,amssymb,mathrsfs}
\usepackage{amsthm}
\usepackage{comment}
\usepackage{rotating}
\usepackage{lscape}
\usepackage{enumerate}
\usepackage{fullpage}
\usepackage{url}
\begin{document}
\begin{center}	
	\textbf{Mexican Drug War: Have the Military Interventions Increased Violence?}
\end{center}

When we start to approach this problem the first to consider is what data is available to analyze it. We are using the Military interventions listed in a non comprehensive list from may 7,2007 - nov 21, 2010) NEXOS paper: \url{http://www.nexos.com.mx/?P=leerarticulo&Article=1943189 }. %Read this again to use their terminology.

The measure of violence that we are using is homicide rate, Y. This could be debatable, maybe a combined measure of different kinds of crimes would be better.

Assumptions:
\begin{itemize}
	\item SUTVA
	\item Unconfoundedness: a very strong assumption is that we have all the covariates that could affect the homicide rates. In other words that we have all covariates, X, such that given X,  W is independent of Y.
	\item That homicide rates, Y, are an accurate measure of violence. 
\end{itemize}

The main idea is to combine synthetic and propensity score matching to address this question. What are the advantages of doing that? (and what's new?)
The current proposal is to use propensity score matching to create pools of acceptable controls for each treated unit (is there some multiple comparison thing going on here? Probably not, we just cared about the observed imbalances, we are not saying anything else.). Furthermore, to get the synthetic match for treated unit $T_i$ we can choose the weights for the units in it's control pool such that the $Y_1^T,\ldots, Y_{I_i}^{T_i}$ is best matched
	

There are 2213 municipalities in the initial control pool, and the numbers per treated unit are:
  % latex table generated in R 2.14.0 by xtable 1.6-0 package
% Thu Sep 27 10:40:57 2012
% \begin{table}[ht]
% \begin{center}
% \begin{tabular}{rc|rc}
% 
%   \hline 
%   \textbf{1 }&   5 &\textbf{10} &  10 \\ 
%   \textbf{2} &   5 &\textbf{11} &   8 \\  
%   \textbf{3} &  12 &\textbf{12 }&  27 \\ 
%   \textbf{4} &  15 & \textbf{13} &  11 \\
%   \textbf{5} &  14 & \textbf{14} &   9 \\ 
%   \textbf{6} &  24 & \textbf{15} &   9 \\ 
%   \textbf{7} &   5 &  \textbf{16} &  10 \\ 
%   \textbf{8} &  20 &\textbf{17} &   6 \\ 
%   \textbf{9} &  18 & \textbf{18 }&  35 \\
% \hline
% \end{tabular}
% \end{center}
% \end{table}


% latex table generated in R 2.14.0 by xtable 1.6-0 package
% Thu Sep 27 14:57:21 2012
\begin{table}[ht]
\begin{center}
\begin{tabular}{ccc|ccc}
  \hline
 \textbf{unit}& number of& Date of first &  \textbf{unit}& number of& Date of first \\ 
 & municipalities& intervention& & municipalities& intervention \\ 
  \hline
\textbf{1} &   5 & 2008 &  \textbf{10} &10 & 2009 \\ 
  \textbf{2} &   5 & 2008 &  \textbf{11} & 8 & 2008 \\ 
  \textbf{3} &  12 & 2010* &  \textbf{12} &27 & 2007 \\ 
  \textbf{4} &  15 & 2009 &  \textbf{13} &11 & 2010* \\ 
  \textbf{5} &  14 & 2007 &   \textbf{14} &9 & 2010* \\ 
  \textbf{6} &  24 & 2008 &   \textbf{15} &9 & 2009 \\ 
  \textbf{7} &   5 & 2010* &  \textbf{16} &10 & 2007 \\ 
  \textbf{8} &  20 & 2009 &   \textbf{17} &6 & 2010* \\ 
  \textbf{9} &  18 & 2008 &  \textbf{18} &35 & 2008 \\ 
   \hline
\end{tabular}
\end{center}
\end{table}

Note that for the data that we're working with, all the regions with $*$ are eliminated from the data set since we have no post intervention information. The data collected spans 1990-2010.

\section{Estimand}
We want to measure the effect of the military interventions in terms of the increase in homicide rates. Following the Rubin Causal Model, let $Y_j(1)$ and $Y_j(0)$ denote the homicide rate of region $j$ one year after it received a military intervention\footnote{We can also estimate the effect two and three years post intervention. However, the uncertainty will increase because there are only three regions with 2007 interventions and an additional six with 2008 interventions.}, and what it would have been at that same point in time if it hadn't received the military intervention. The estimand of interest is the average causal effect of the military intervention for the regions that were intervened. That is $$\tau=\overline{Y}(1)-\overline{Y}(0)=\frac{\sum_j Y_j(1)-Y_j(0)}{J}.$$ % do we want to weigh these?
A common approach is to assume $Y_j(1)$ is observed for all treated units. Let $N_j$ denote the number of municipalities that correspond to region $j$, then 
$$Y_j(1) = \sum_{i=1}^{N_j}w_{ij}Y_{ij}(1),$$
where  $\textrm{Pop}_{j}= \sum_i^{N_j}\textrm{Pop}_{ij}$, and $$w_{ij}= \frac{\textrm{Pop}_{ij}}{\textrm{Pop}_{j}}.$$ 
However, $Y_j(0)$ is missing for all $j$. Following the reasoning above, $$Y_j(0) = \sum_{i=1}^{N_j}w_{ij}Y_{ij}(0),$$ and all $Y_{ij}(0)$ are unobserved.
\section{Matching Procedure and ``Naive'' Analysis}

We attempt to use the information of all other municipalities to estimate each $Y_{ij}(0)$ to obtain an estimate $Y_j(0)$. How will we do that? The idea is to use propensity score matching to identify good matches for each treated municipality.

To follow the guidelines for observational studies we will first clarify what the analysis protocol will be, that will determine the way the balance checks will be performed to choose an estimated propensity score that leads to an acceptable balance.
Let $M_{ij}$ be the number of municipalities matched to the $i$th municipality in region $j$. Let $$\textrm{PopM}_{ij}=\sum_{k=1}^{M_{ij}}\textrm{PopM}_{ijk}$$ denote the total population of all $M_{ij}$ municipalities matched to the $i$th treated municipality in region $j$. Then 
$$\hat{Y}_{ij}(0) =\sum_{k=1}^{M_{ij}}v_{ijk}Y_{ijk}(0),$$ where $v_{ijk}=\frac{\textrm{PopM}_{ijk}}{\textrm{PopM}_{ij}}.$
Therefore,
$$\hat{Y}_{j}(0) =\sum_{i=1}^{N_j}w_{ij}\hat{Y}_{ij}(0)=\sum_{i=1}^{N_j}w_{ij}\sum_{k=1}^{M_{ij}}v_{ijk}Y_{ijk}(0),$$
and
$\hat{\tau}=$


\section{Comments}
Perhaps a more comprehensive way of approaching this problem is to analyze the homicide rate time series using Synthetic Matching.

	
\end{document}